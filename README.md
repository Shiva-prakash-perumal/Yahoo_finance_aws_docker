# ğŸ“ˆ Yahoo Finance Data Pipeline on AWS

This project builds a robust, Dockerized data pipeline to fetch and transform stock data from the Yahoo Finance API, orchestrated using AWS Batch, and monitored via CloudWatch and SNS. It's designed for scalability, reliability, and seamless integration into AWS cloud environments.

---

## ğŸ§° Tech Stack

- **Python** â€“ Fetching and transforming stock data
- **Docker** â€“ Containerizing scripts
- **AWS Batch** â€“ Job orchestration
- **AWS ECR** â€“ Image registry
- **AWS S3** â€“ Data storage (raw & transformed)
- **AWS Secrets Manager** â€“ API key management
- **AWS CloudWatch + SNS** â€“ Failure monitoring and alerting

---

## ğŸ“Š Architecture

![Architecture Diagram](./architecture_diagram.png)

1. **Terminal (CLI)** triggers Docker build and AWS Batch job.
2. **Fetch Script** pulls data from Yahoo Finance using secure credentials from Secrets Manager.
3. **Transform Script** cleans and structures the data.
4. **Docker** image is built and pushed to **AWS ECR**.
5. **AWS Batch** runs the containerized job.
6. Processed and raw data are stored in **Amazon S3**.
7. **CloudWatch** monitors job status; on failure, **SNS** sends alerts to subscribed channels (email/SMS).

---

## ğŸš€ How to Use

### ğŸ”§ Step 1: Clone the Repository

```bash
git clone https://github.com/Shiva-prakash-perumal/Yahoo_finance_aws_docker.git
cd Yahoo_finance_aws_docker
```

### ğŸ³ Step 2: Build Docker Image

```bash
docker build -t yahoo-finance-pipeline .
```

### ğŸ“¦ Step 3: Push Image to AWS ECR

```bash
aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <aws_account_id>.dkr.ecr.<region>.amazonaws.com
docker tag yahoo-finance-pipeline <ecr_repo_url>
docker push <ecr_repo_url>
```

### â˜ï¸ Step 4: Create Batch Environment

- Choose **Fargate**
- Assign `AWSServiceRoleForBatch`
- Set job role with `ecs-tasks.amazonaws.com` trust

### ğŸ“„ Step 5: Submit Batch Job

Manually or through EventBridge/CloudWatch

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ fetch_data.py
â”œâ”€â”€ transform_data.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ diagram.png
â”œâ”€â”€ README.md
```

---

## ğŸ“¡ Failure Notifications

If a Batch job fails:
- **CloudWatch Events** detect the failure
- **SNS Topic** triggers
- **Email/SMS/Slack alerts** are sent to registered receivers

---

## ğŸ’¡ Improvements To Explore

- Add schema validation before writing to S3
- Schedule jobs using EventBridge
- Visualize trends using Amazon QuickSight or Streamlit
- Implement retries for transient API failures

---

## ğŸ™‹â€â™‚ï¸ Author

**Shiva Prakash Perumal**  
[GitHub](https://github.com/Shiva-prakash-perumal) | [LinkedIn](https://linkedin.com/in/shiva-prakash-perumal)

---

## ğŸªª License

This project is licensed under the [MIT License](LICENSE).